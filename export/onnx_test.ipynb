{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cosine\n",
    "import pickle\n",
    "\n",
    "def preprocess_image(image_path, input_size=(224, 224)):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize(input_size)\n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array / 255.0\n",
    "    image_array = image_array.astype(np.float32)\n",
    "    image_array = np.transpose(image_array[np.newaxis, ...], (0,3,1,2))\n",
    "    return image_array\n",
    "\n",
    "def run_inference(image_path, model_path):\n",
    "    session = ort.InferenceSession(model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    input_data = preprocess_image(image_path)\n",
    "    outputs = session.run(None, {input_name: input_data})\n",
    "    probabilities = softmax(outputs[0][0])\n",
    "    predicted_class = np.argmax(probabilities)\n",
    "    return predicted_class, probabilities, outputs[1]\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def load_mean_embedding(file_path):\n",
    "    \"\"\"평균 임베딩 로드 함수\n",
    "\n",
    "    Args :\n",
    "        - file_path : pickle file path\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        print(data.shape)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "def is_eye_image(extract_embedding, mean_embedding, threshold=0.65):\n",
    "    # Flatten the embeddings to 1-D arrays\n",
    "    extract_embedding_flat = extract_embedding.squeeze().flatten()\n",
    "    mean_embedding_flat = mean_embedding.flatten()\n",
    "    print(extract_embedding_flat.shape, mean_embedding_flat.shape)\n",
    "    similarity = 1 - cosine(extract_embedding_flat, mean_embedding_flat)\n",
    "    result = similarity > threshold\n",
    "\n",
    "    return result, similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960,)\n",
      "\n",
      "Processing class directory: 0\n",
      "=== 이미지 유사성 판단 ===\n",
      "(47040,) (960,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-01-18 10:03:42.874166835 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.bn1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874255220 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.bn1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874263677 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.bn1.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874270533 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.bn1.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874277638 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.2.0.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874285002 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.2.0.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874291605 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.2.1.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874298229 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.2.1.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874304828 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.2.2.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874311359 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.2.2.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874321004 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.4.0.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874327642 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.4.0.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874334552 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.4.1.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874355971 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.4.1.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874361752 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.5.0.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874367323 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.5.0.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874372792 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.5.1.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874378690 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.5.1.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874386110 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.5.2.se.conv_reduce.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874391968 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.blocks.5.2.se.conv_expand.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874397922 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.conv_head.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874403727 [W:onnxruntime:, graph.cc:1348 Graph] Initializer model.classifier.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874409519 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_697 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874415107 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_700 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874420721 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_703 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874437479 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_706 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874444217 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_709 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874461035 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_712 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874466122 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_715 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874471666 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_718 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874476649 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_721 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874481553 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_724 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874486493 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_727 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874491435 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_730 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874496406 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_733 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874503354 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_736 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874508375 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_739 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874513480 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_742 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874518466 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_745 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874523466 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_748 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874528384 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_751 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874533298 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_754 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874538196 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_757 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874543234 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_760 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874549931 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_763 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874554897 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_766 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874559829 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_769 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874564806 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_772 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874569962 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_775 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874574878 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_778 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874579790 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_781 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874584782 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_784 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874590011 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_787 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874596504 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_790 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874601597 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_793 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874606787 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_796 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874611777 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_799 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874616728 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_802 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874621687 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_805 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874627716 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_808 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874632716 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_811 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874637715 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_814 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874644415 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_817 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874649443 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_820 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874654775 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_823 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874660113 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_826 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874664995 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_829 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874670252 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_832 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874675411 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_835 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874680289 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_838 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874685232 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_841 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874691872 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_844 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874696951 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_847 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874701919 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_850 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874706816 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_853 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874711785 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_856 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874716909 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_859 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874721947 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_862 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874726988 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_865 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874732205 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_868 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874738835 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_871 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874743939 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_874 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874748941 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_877 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874754012 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_880 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874759191 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_883 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874764310 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_886 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874769221 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_889 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874774102 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_892 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874779031 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_895 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874785478 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_898 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874790390 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_901 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874795431 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_904 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874800389 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_907 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874805477 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_910 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874810589 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_913 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874815987 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_916 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874820958 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_919 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874828677 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_922 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874835815 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_925 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874840853 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_928 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874846424 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_931 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874851504 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_934 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874856475 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_937 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874861667 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_940 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874866778 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_943 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874871808 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_946 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874876791 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_949 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874883243 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_952 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874888240 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_955 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874893192 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_958 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874898436 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_961 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2025-01-18 10:03:42.874903508 [W:onnxruntime:, graph.cc:1348 Graph] Initializer onnx::Conv_964 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (47040,) and (960,) not aligned: 47040 (dim 0) != 960 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m predicted_class, probabilities, embedding \u001b[38;5;241m=\u001b[39m run_inference(image_path, model_path)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== 이미지 유사성 판단 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m result, similarity \u001b[38;5;241m=\u001b[39m is_eye_image(\n\u001b[1;32m     26\u001b[0m     embedding, mean_emb, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.65\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m눈 이미지, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(similarity,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m눈 이미지 아님, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(similarity,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mis_eye_image\u001b[0;34m(extract_embedding, mean_embedding, threshold)\u001b[0m\n\u001b[1;32m     47\u001b[0m mean_embedding_flat \u001b[38;5;241m=\u001b[39m mean_embedding\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(extract_embedding_flat\u001b[38;5;241m.\u001b[39mshape, mean_embedding_flat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 49\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine(extract_embedding_flat, mean_embedding_flat)\n\u001b[1;32m     50\u001b[0m result \u001b[38;5;241m=\u001b[39m similarity \u001b[38;5;241m>\u001b[39m threshold\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, similarity\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/scipy/spatial/distance.py:694\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correlation(u, v, w\u001b[38;5;241m=\u001b[39mw, centered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/scipy/spatial/distance.py:644\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    643\u001b[0m     vw, uw \u001b[38;5;241m=\u001b[39m v, u\n\u001b[0;32m--> 644\u001b[0m uv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(u, vw)\n\u001b[1;32m    645\u001b[0m uu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(u, uw)\n\u001b[1;32m    646\u001b[0m vv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(v, vw)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (47040,) and (960,) not aligned: 47040 (dim 0) != 960 (dim 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 이미지가 있는 기본 디렉토리 경로\n",
    "base_dir = \"/workspace/a-eye-lab-research/export/test_data\"\n",
    "model_path = \"/workspace/model_quantized.onnx\"\n",
    "\n",
    "mean_emb = load_mean_embedding(\"/workspace/a-eye-lab-research/notebook/eye_detection/embedding_pkl/mean_embedding_tuning_250118.pkl\")\n",
    "# 모든 하위 디렉토리(0, 1)를 순회\n",
    "for class_dir in os.listdir(base_dir):\n",
    "    class_path = os.path.join(base_dir, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        print(f\"\\nProcessing class directory: {class_dir}\")\n",
    "        \n",
    "        # 각 클래스 디렉토리 내의 모든 이미지 파일을 순회\n",
    "        for image_file in os.listdir(class_path):\n",
    "            if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "                \n",
    "                # 추론 실행\n",
    "                predicted_class, probabilities, embedding = run_inference(image_path, model_path)\n",
    "\n",
    "\n",
    "                print(\"=== 이미지 유사성 판단 ===\")\n",
    "\n",
    "                result, similarity = is_eye_image(\n",
    "                    embedding, mean_emb, threshold=0.65\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    f\"눈 이미지, {np.round(similarity,2)}\"\n",
    "                    if result\n",
    "                    else f\"눈 이미지 아님, {np.round(similarity,2)}\"\n",
    "                )\n",
    "                \n",
    "                # 결과 출력\n",
    "                print(f\"\\nImage: {image_file}\")\n",
    "                print(f\"True class: {class_dir}\")\n",
    "                print(f\"Predicted class: {predicted_class}\")\n",
    "                print(f\"Probabilities: [{probabilities[0]:.4f}, {probabilities[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
